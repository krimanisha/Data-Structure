<h3>Analysis of Algorithms:-</h3> Writing different algorithms for a given set of problem and analyzing it in terms of time and space. <br>
-> Algorithms Analysising is very important as it will helps us to use right algorithms for a problem set which will result in saving time and space.<br>

Drawback:- Writing all the algorithms and then analyzing will consume more time. So, Asympotic Algorithms is introduced.<br>

Asympotic Algorithms:- Measuring order of growth of a program or algorithms in terms of input size.<br>

Order of Growth:-<br>
Method 1-<br>
A function f(n) is said to be growing faster than g(n) if -<br>
i) 
ii)
<br>
Method 2-<br>
i) Ignore lower order terms<br>
ii) Ignore leading constant<br>

How do we know which terms are lower order?<br>
c < loglogn < logn < n^1/3 < n^1/2 < n^1/2 < n < n^2 < n^3 <n^4 < 2^n < n^n<br>

Asympotic Notation:- <br>

There are total 3 cases:-<br>
1) Best Case    2) Average Case     3) Worst Case<br>
--> Average Case is impratical to guess.<br>
--> Worst Cases are only considered when there are more than 1 case in algorithm.<br>

Mathematical Notation:-<br>
1) Big O - Represents exact or upper bound.<br>
2) Thetha - Represents exact bound.<br>
3) Omega - Represents exact or lower bound.<br>





